<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>模型压缩 | fei's Blog</title><meta name="author" content="微冷"><meta name="copyright" content="微冷"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="模型压缩技术概述 模型压缩问题定义 因为嵌入式设备的算力和内存有限，因此深度学习模型需要经过模型压缩后，方才能部署到嵌入式设备上。 模型压缩问题的定义可以从三个角度出发:  模型压缩的收益:  计算: 减少浮点运算量（FLOPs），降低延迟（Latency） 存储: 减少内存占用，提高 GPU&#x2F;NPU 计算利用率   公式定义模型压缩问题: minModelsize(Policyi)minMode">
<meta property="og:type" content="article">
<meta property="og:title" content="模型压缩">
<meta property="og:url" content="https://afei786.github.io/2024/02/02/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/index.html">
<meta property="og:site_name" content="fei&#39;s Blog">
<meta property="og:description" content="模型压缩技术概述 模型压缩问题定义 因为嵌入式设备的算力和内存有限，因此深度学习模型需要经过模型压缩后，方才能部署到嵌入式设备上。 模型压缩问题的定义可以从三个角度出发:  模型压缩的收益:  计算: 减少浮点运算量（FLOPs），降低延迟（Latency） 存储: 减少内存占用，提高 GPU&#x2F;NPU 计算利用率   公式定义模型压缩问题: minModelsize(Policyi)minMode">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/J3bTOk4UgtAyHam.jpg">
<meta property="article:published_time" content="2024-02-02T08:10:23.000Z">
<meta property="article:modified_time" content="2024-02-02T14:40:21.379Z">
<meta property="article:author" content="微冷">
<meta property="article:tag" content="剪枝">
<meta property="article:tag" content="量化">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/12/17/J3bTOk4UgtAyHam.jpg"><link rel="shortcut icon" href="https://pic.imgdb.cn/item/659f761b871b83018a34767d.png"><link rel="canonical" href="https://afei786.github.io/2024/02/02/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/pwa/manifest.json"/><link rel="apple-touch-icon" sizes="180x180" href="/pwa/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/pwa/32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/pwa/16.png"/><link rel="mask-icon" href="/pwa/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '模型压缩',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-02 22:40:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/659f7607871b83018a343643.jpg" onerror="onerror=null;src='https://pic.imgdb.cn/item/659f76fb871b83018a3742dc.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/12/17/J3bTOk4UgtAyHam.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="fei's Blog"><span class="site-name">fei's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">模型压缩</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-02T08:10:23.000Z" title="发表于 2024-02-02 16:10:23">2024-02-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-02T14:40:21.379Z" title="更新于 2024-02-02 22:40:21">2024-02-02</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>11分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="模型压缩"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>模型压缩技术概述</h1>
<h2 id="模型压缩问题定义">模型压缩问题定义</h2>
<p>因为嵌入式设备的算力和内存有限，因此深度学习模型需要经过模型压缩后，方才能部署到嵌入式设备上。</p>
<p>模型压缩问题的定义可以从三个角度出发:</p>
<ul>
<li>模型压缩的收益:
<ul>
<li>计算: 减少浮点运算量（FLOPs），降低延迟（Latency）</li>
<li>存储: 减少内存占用，提高 GPU/NPU 计算利用率</li>
</ul>
</li>
<li>公式定义模型压缩问题: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">(</mo><mi>P</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>c</mi><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">minModelsize(Policy_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">min</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>模型压缩问题的约束: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo stretchy="false">(</mo><mi>P</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>c</mi><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>&gt;</mo><mo>=</mo><mi>a</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">accuracy(Policy_i)&gt;=accuracy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">cc</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">cy</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">cc</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">cy</span></span></span></span></li>
</ul>
<p>我们知道，一定程度上，网络越深，参数越多，模型也会越复杂，但其最终效果也越好，而模型压缩算法是旨在将一个庞大而复杂的预训练模型转化为一个精简的小模型。</p>
<h2 id="模型压缩方法分类">模型压缩方法分类</h2>
<p>按照压缩过程对网络结构的破坏程度，《解析卷积神经网络》一书中将模型压缩技术分为“前端压缩”和“后端压缩”两部分:</p>
<h3 id="前端压缩">前端压缩</h3>
<p>是指在不改变原网络结构的压缩技术，主要包括知识蒸馏、轻量级网络（紧凑的模型结构设计）以及滤波器（filter）层面的剪枝（结构化剪枝）等；</p>
<h3 id="后端压缩">后端压缩</h3>
<p>是指包括低秩近似、未加限制的剪枝（非结构化剪枝/稀疏）、参数量化以及二值网络等，目标在于尽可能减少模型大小，会对原始网络结构造成极大程度的改造。</p>
<h3 id="总结">总结</h3>
<p>前端压缩几乎不改变原有网络结构（仅仅只是在原模型基础上减少了网络的层数或者滤波器个数），后端压缩对网络结构有不可逆的大幅度改变，造成原有深度学习库、甚至硬件设备不兼容改变之后的网络。其维护成本很高。</p>
<h2 id="模型压缩方法举例">模型压缩方法举例</h2>
<p>工业界主流的模型压缩方法有：知识蒸馏（Knowledge Distillation，KD）轻量化模型架构（也叫紧凑的模型设计）、剪枝（Pruning）、量化（Quantization）。各个模型压缩方法总结如下：</p>
<table>
<thead>
<tr>
<th>模型压缩方法</th>
<th>描述</th>
<th>涉及的网络层</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>知识蒸馏</td>
<td>属于迁移学习的一种，主要思想是将学习能力强的复杂教师模型中的“知识”迁移到简单的学生模型中。</td>
<td>卷积和全连接层</td>
<td>经典KD论文，属于蒸 &quot;logits&quot;方法，将Teacher Network输出的soft label作为标签来训练Student Network。必须重新训练模型。</td>
</tr>
<tr>
<td>轻量化模型架构</td>
<td>轻量级网络的核心是在尽量保持精度的前提下，从体积和速度两方面对网络进行轻量化改造。</td>
<td>卷积层/卷积模块</td>
<td>Mobilenet 提出深度可分离卷积；shufflenetv2 论文 提出的四个高效网络设计的实用指导思想；RepVGG 提出重参数化思想。都需要重新设计 backbone 和和重新训练模型。</td>
</tr>
<tr>
<td>剪枝</td>
<td>将权重低于阈值的连接都从网络中删除。</td>
<td>卷积层和全连接层</td>
<td>韩松2016年Deep Compression属于开山之作，剪枝步骤：正常训练，删除网络中权重低于阈值的连接层，重新训练。需要重新训练模型。</td>
</tr>
<tr>
<td>量化</td>
<td>指将神经网络的浮点算法转换为定点算法</td>
<td>卷积、全连接、激活、BN层等</td>
<td>TensoRT框架中的基于 KL 散度方法的INT8量化策略是主流技术。PTQ 训练后量化方法不需要重新训练模型。</td>
</tr>
</tbody>
</table>
<h1>知识蒸馏</h1>
<p>一个复杂模型可由多个简单模型或者强约束条件训练得到。复杂模型特点是性能好，但其参数量大，计算效率低。小模型特点是计算效率高，但是其性能较差。知识蒸馏是让小模型去拟合大模型，从而让小模型学到与大模型相似的函数映射。使其保持其快速的计算速度前提下，同时拥有复杂模型的性能，达到模型压缩的目的。模型蒸馏的关键在于监督特征的设计，例如使用 Soft Target（软标签KD） 所提供的类间相似性作为依据 [9]，或使用大模型的中间层特征图 [10] 或 attention map [11] 作为暗示，对小网络进行训练。整体的框架图如图下所示。<br>
<img src="https://pic.imgdb.cn/item/65bcad87871b83018a18be96.jpg" alt=""></p>
<h1>轻量化模型架构</h1>
<p>关于如何手动设计轻量级网络的研究，目前还没有广泛通用的准则，只有一些指导思想，和针对不同芯片平台（不同芯片架构）的一些设计总结，建议大家从经典论文中吸取指导思想和建议，然后自己实际做各个硬件平台的部署和模型性能测试。</p>
<h2 id="如何设计高效CNN架构">如何设计高效CNN架构</h2>
<p>一些结论</p>
<ul>
<li>分析模型的推理性能得结合具体的推理平台（常见如：英伟达 GPU、移动端 ARMCPU、端侧 NPU 芯片等）；目前已知影响 CNN 模型推理性能的因素包括: 算子计算量 FLOPs（参数量 Params）、卷积 block 的内存访问代价（访存带宽）、网络并行度等。但相同硬件平台、相同网络架构条件下， FLOPs 加速比与推理时间加速比成正比。</li>
<li>建议对于轻量级网络设计应该考虑直接 metric（例如速度 speed），而不是间接 metric（例如 FLOPs）。</li>
<li>FLOPs 低不等于 latency 低，尤其是在有加速功能的硬体 (GPU、DSP 与 TPU)上不成立，得结合具硬件架构具体分析。</li>
<li>不同网络架构的 CNN 模型，即使是 FLOPs 相同，但其 MAC 也可能差异巨大。</li>
<li>Depthwise 卷积操作对于流水线型 CPU、ARM 等移动设备更友好，对于并行计算能力强的 GPU 和具有加速功能的硬件（专用硬件设计-NPU 芯片）上比较没有效率。Depthwise 卷积算子实际上是使用了大量的低 FLOPs、高数据读写量的操作。因为这些具有高数据读写量的操作，再加上多数时候 GPU 芯片算力的瓶颈在于访存带宽，使得模型把大量的时间浪费在了从显存中读写数据上，从而导致 GPU 的算力没有得到“充分利用”。结论来源知乎文章-FLOPs与模型推理速度和论文 G-GhostNet。</li>
</ul>
<p>一些建议</p>
<ul>
<li>在大多数的硬件上，channel 数为 16 的倍数比较有利高效计算。如海思 351x 系列芯片，当输入通道为 4 倍数和输出通道数为 16 倍数时，时间加速比会近似等于 FLOPs 加速比，有利于提供 NNIE 硬件计算利用率。(来源海思 351X 芯片文档和 MobileDets 论文)</li>
<li>低 channel 数的情况下 (如网路的前几层)，在有加速功能的硬件使用普通 convolution 通常会比 separable convolution 有效率。（来源 MobileDets 论文）</li>
<li>shufflenetv2 论文 提出的四个高效网络设计的实用指导思想: G1同样大小的通道数可以最小化 MAC、G2-分组数太多的卷积会增加 MAC、G3-网络碎片化会降低并行度、G4-逐元素的操作不可忽视。</li>
<li>GPU 芯片上 3<em>3 卷积非常快，其计算密度（理论运算量除以所用时间）可达 1</em>1 和 5*5 卷积的四倍。（来源 RepVGG 论文）</li>
<li>从解决梯度信息冗余问题入手，提高模型推理效率。比如 CSPNet 网络。</li>
<li>从解决 DenseNet 的密集连接带来的高内存访问成本和能耗问题入手，如 VoVNet 网络，其由 OSA（One-Shot Aggregation，一次聚合）模块组成。</li>
</ul>
<h2 id="轻量级模型部署总结">轻量级模型部署总结</h2>
<p>在阅读和理解经典的轻量级网络 mobilenet 系列、MobileDets、shufflenet 系列、cspnet、vovnet、repvgg 等论文的基础上，做了以下总结：</p>
<ul>
<li>低算力设备-手机移动端 cpu 硬件，考虑 mobilenetv1(深度可分离卷机架构-低 FLOPs)、低 FLOPs 和 低MAC的shuffletnetv2（channel_shuffle 算子在推理框架上可能不支持）</li>
<li>专用 asic 硬件设备-npu 芯片（地平线 x3/x4 等、海思 3519、安霸cv22 等），分类、目标检测问题考虑 cspnet 网络(减少重复梯度信息)、repvgg2（即 RepOptimizer: vgg 型直连架构、部署简单）</li>
<li>英伟达 gpu 硬件-t4 芯片，考虑 repvgg 网络（类 vgg 卷积架构-高并行度有利于发挥 gpu 算力、单路架构省显存/内存，问题: INT8 PTQ 掉点严重）</li>
</ul>
<p>MobileNet block (深度可分离卷积 block, depthwise separable convolution block)在有加速功能的硬件（专用硬件设计-NPU 芯片）上比较没有效率。</p>
<p>这个结论在 CSPNet 和 MobileDets 论文中都有提到。</p>
<p>除非芯片厂商做了定制优化来提高深度可分离卷积 block 的计算效率，比如地平线机器人 x3 芯片对深度可分离卷积 block 做了定制优化。</p>
<p>下表是 MobileNetv2 和 ResNet50 在一些常见 NPU 芯片平台上做的性能测试结果。<br>
<img src="https://pic.imgdb.cn/item/65bcaefa871b83018a1d744b.jpg" alt=""><br>
以上，均是看了轻量级网络论文总结出来的一些不同硬件平台部署轻量级模型的经验，实际结果还需要自己手动运行测试。</p>
<h1>模型剪枝</h1>
<p>深度学习模型中一般存在着大量冗余的参数，将权重矩阵中相对“不重要”的权值剔除（即置为 0），可达到降低计算资源消耗和提高实时性的效果，而对应的技术则被称为模型剪枝。<br>
<img src="https://pic.imgdb.cn/item/65bcaf3f871b83018a1e9dfb.jpg" alt=""><br>
来源论文Han et al. Learning both Weights and Connections for Efficient Neural Networks, NIPS 2015</p>
<p>剪枝算法步骤：</p>
<ol>
<li>正常训练模型；</li>
<li>模型剪枝；</li>
<li>重新训练模型<br>
以上三个步骤反复迭代进行，直到模型精度达到目标，则停止训练。</li>
</ol>
<p>模型剪枝算法根据粒度的不同，可以粗分为4种粒度：</p>
<ol>
<li>细粒度剪枝(fine-grained)：对连接或者神经元进行剪枝，它是粒度最小的剪枝。</li>
<li>向量剪枝(vector-level)：它相对于细粒度剪枝粒度更大，属于对卷积核内部(intra-kernel)的剪枝。</li>
<li>核剪枝(kernel-level)：去除某个卷积核，它将丢弃对输入通道中对应计算通道的响应。</li>
<li>滤波器剪枝(Filter-level)：对整个卷积核组进行剪枝，会造成推理过程中输出特征通道数的改变。</li>
</ol>
<h1>模型量化</h1>
<p>模型量化是指将神经网络的浮点算法转换为定点。量化有一些相似的术语，低精度（Low precision）可能是常见的。</p>
<ul>
<li>低精度模型表示模型权重数值格式为 FP16（半精度浮点）或者 INT8（8位的定点整数），但是目前低精度往往就指代 INT8。</li>
<li>常规精度模型则一般表示模型权重数值格式为 FP32（32位浮点，单精度）。</li>
<li>混合精度（Mixed precision）则在模型中同时使用 FP32 和 FP16 的权重数值格式。 FP16 减少了一半的内存大小，但有些参数或操作符必须采用 FP32 格式才能保持准确度。</li>
</ul>
<p>模型量化过程可以分为两部分：将模型从 FP32 转换为 INT8（即量化算术过程），以及使用 INT8 进行推理。</p>
<h2 id="模型量化的方案">模型量化的方案</h2>
<p>在实践中将浮点模型转为量化模型的方法有以下三种方法：</p>
<ol>
<li>data free：不使用校准集，传统的方法直接将浮点参数转化成量化数，使用上非常简单，但是一般会带来很大的精度损失，但是高通最新的论文 DFQ 不使用校准集也得到了很高的精度。</li>
<li>calibration：基于校准集方案，通过输入少量真实数据进行统计分析。很多芯片厂商都提供这样的功能，如 tensorRT、高通、海思、地平线、寒武纪</li>
<li>finetune：基于训练 finetune 的方案，将量化误差在训练时仿真建模，调整权重使其更适合量化。好处是能带来更大的精度提升，缺点是要修改模型训练代码，开发周期较长。</li>
</ol>
<p>按照量化阶段的不同，量化方法分为以下两种：</p>
<ul>
<li>Post-training quantization PTQ（训练后量化、离线量化）；</li>
<li>Quantization-aware training QAT（训练时量化，伪量化，在线量化）。</li>
</ul>
<h2 id="量化的分类">量化的分类</h2>
<p>目前已知的加快推理速度概率较大的量化方法主要有：</p>
<ol>
<li>二值化，其可以用简单的位运算来同时计算大量的数。对比从 nvdia gpu 到 x86 平台，1bit 计算分别有 5 到128倍的理论性能提升。且其只会引入一个额外的量化操作，该操作可以享受到 SIMD（单指令多数据流）的加速收益。</li>
<li>线性量化(最常见)，又可细分为非对称，对称和 ristretto 几种。在 nvdia gpu，x86、arm 和 部分 AI 芯片平台上，均支持 8bit 的计算，效率提升从 1 倍到 16 倍不等，其中 tensor core 甚至支持 4bit计算，这也是非常有潜力的方向。线性量化引入的额外量化/反量化计算都是标准的向量操作，因此也可以使用 SIMD 进行加速，带来的额外计算耗时不大。</li>
<li>对数量化，一种比较特殊的量化方法。两个同底的幂指数进行相乘，那么等价于其指数相加，降低了计算强度。同时加法也被转变为索引计算。目前 nvdia gpu，x86、arm 三大平台上没有实现对数量化的加速库，但是目前已知海思 351X 系列芯片上使用了对数量化。</li>
</ol>
<h1>压缩方法总结</h1>
<ul>
<li>一般情况下，参数剪枝，特别是非结构化剪枝，能大大压缩模型大小，且不容易丢失分类精度。对于需要稳定的模型分类的应用，非结构化剪枝成为首要选择。</li>
<li>如果需要一次性端对端训练得到压缩与加速后模型，可以利用基于紧性滤波设计的深度神经网络压缩与加速方法。</li>
<li>影响神经网络推理速度主要有 4 个因素：计算量 FLOPs、内存访问代价 MAC、计算并行度、硬件平台架构与特性（算力、GPU 内存带宽）。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://afei786.github.io">微冷</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://afei786.github.io/2024/02/02/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/">https://afei786.github.io/2024/02/02/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://afei786.github.io" target="_blank">fei's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%89%AA%E6%9E%9D/">剪枝</a><a class="post-meta__tags" href="/tags/%E9%87%8F%E5%8C%96/">量化</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2023/12/17/J3bTOk4UgtAyHam.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/21/%E9%9D%A2%E8%AF%95%E9%A2%98/" title="面试题"><img class="cover" src="https://s2.loli.net/2023/12/17/OdmekDlcEhCwSZN.jpg" onerror="onerror=null;src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">面试题</div></div></a></div><div class="next-post pull-right"><a href="/2024/02/01/transformer%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" title="transformer模型详解及代码实现"><img class="cover" src="https://s2.loli.net/2023/12/17/J3bTOk4UgtAyHam.jpg" onerror="onerror=null;src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">transformer模型详解及代码实现</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://pic.imgdb.cn/item/659f7607871b83018a343643.jpg" onerror="this.onerror=null;this.src='https://pic.imgdb.cn/item/659f76fb871b83018a3742dc.gif'" alt="avatar"/></div><div class="author-info__name">微冷</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dashboard"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/afei786" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:chenxinsunfei@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">模型压缩技术概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.</span> <span class="toc-text">模型压缩问题定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB"><span class="toc-number">1.2.</span> <span class="toc-text">模型压缩方法分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E7%AB%AF%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.2.1.</span> <span class="toc-text">前端压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%E7%AB%AF%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.2.2.</span> <span class="toc-text">后端压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B8%BE%E4%BE%8B"><span class="toc-number">1.3.</span> <span class="toc-text">模型压缩方法举例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">知识蒸馏</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">轻量化模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E9%AB%98%E6%95%88CNN%E6%9E%B6%E6%9E%84"><span class="toc-number">3.1.</span> <span class="toc-text">如何设计高效CNN架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E6%80%BB%E7%BB%93"><span class="toc-number">3.2.</span> <span class="toc-text">轻量级模型部署总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">模型剪枝</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">模型量化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96%E7%9A%84%E6%96%B9%E6%A1%88"><span class="toc-number">5.1.</span> <span class="toc-text">模型量化的方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8F%E5%8C%96%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">5.2.</span> <span class="toc-text">量化的分类</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">压缩方法总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/21/docker-vscode/" title="docker-vscode"><img src="https://s2.loli.net/2023/12/17/h6wHkYULnpNROsG.jpg" onerror="this.onerror=null;this.src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="docker-vscode"/></a><div class="content"><a class="title" href="/2024/06/21/docker-vscode/" title="docker-vscode">docker-vscode</a><time datetime="2024-06-21T14:09:53.000Z" title="发表于 2024-06-21 22:09:53">2024-06-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/11/my-information/" title="my-information"><img src="https://s2.loli.net/2023/12/17/pvLabdPRhsXr819.jpg" onerror="this.onerror=null;this.src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="my-information"/></a><div class="content"><a class="title" href="/2024/06/11/my-information/" title="my-information">my-information</a><time datetime="2024-06-11T14:16:40.000Z" title="发表于 2024-06-11 22:16:40">2024-06-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/06/10/docker-nvidia/" title="docker-nvidia"><img src="https://s2.loli.net/2023/12/17/h6wHkYULnpNROsG.jpg" onerror="this.onerror=null;this.src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="docker-nvidia"/></a><div class="content"><a class="title" href="/2024/06/10/docker-nvidia/" title="docker-nvidia">docker-nvidia</a><time datetime="2024-06-10T14:49:18.000Z" title="发表于 2024-06-10 22:49:18">2024-06-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/26/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%E7%AF%87/" title="算法总结篇"><img src="https://s2.loli.net/2023/12/17/OdmekDlcEhCwSZN.jpg" onerror="this.onerror=null;this.src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="算法总结篇"/></a><div class="content"><a class="title" href="/2024/02/26/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%E7%AF%87/" title="算法总结篇">算法总结篇</a><time datetime="2024-02-26T08:57:50.000Z" title="发表于 2024-02-26 16:57:50">2024-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/21/%E9%9D%A2%E8%AF%95%E9%A2%98/" title="面试题"><img src="https://s2.loli.net/2023/12/17/OdmekDlcEhCwSZN.jpg" onerror="this.onerror=null;this.src='https://pic.imgdb.cn/item/659f7624871b83018a3495b7.jpg'" alt="面试题"/></a><div class="content"><a class="title" href="/2024/02/21/%E9%9D%A2%E8%AF%95%E9%A2%98/" title="面试题">面试题</a><time datetime="2024-02-21T10:59:48.000Z" title="发表于 2024-02-21 18:59:48">2024-02-21</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/12/17/J3bTOk4UgtAyHam.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 微冷</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://butterfly.js.org/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>